{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBjVwYpHJ7ra"
   },
   "source": [
    "# Transformer Network Application: Question Answering\n",
    "\n",
    "Welcome to Week 4's second ungraded lab, and the last lab of the course! Congratulations on making it this far. In this notebook you'll explore another application of the transformer architecture that you built.\n",
    "\n",
    "**After this assignment you'll be able to**:\n",
    "\n",
    "* Perform extractive Question Answering \n",
    "* Fine-tune a pre-trained transformer model to a custom dataset\n",
    "* Implement a QA model in TensorFlow and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SoRb7ykXJ_C4"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "\n",
    "- [1 - Extractive Question Answering](#1)\n",
    "    - [1.1 - Data Cleaning](#1-1)\n",
    "    - [1.2 - Tokenize and Align Labels with ðŸ¤— Library](#1-2)\n",
    "- [2 - Training](#2)\n",
    "    - [2.1 TensorFlow implementation](#2-1)\n",
    "    - [2.2 PyTorch implementation](#2-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0k56ZVXLDbi"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Extractive Question Answering\n",
    "\n",
    "Question answering (QA) is a task of natural language processing that aims to automatically answer questions. The goal of *extractive* QA is to identify the portion of the text that contains the answer to a question. For example, when tasked with answering the question 'When will Jane go to Africa?' given the text data 'Jane visits Africa in September', the question answering model will highlight 'September'.\n",
    "\n",
    "* You will use a variation of the Transformer model you built in the last assignment to answer questions about stories.\n",
    "* You will implement extractive QA model in TensorFlow and in PyTorch.\n",
    "\n",
    "**Recommendation:**\n",
    "* If you are interested, check out the [Course 4: Natural Language Processing with Attention Models](https://www.coursera.org/learn/attention-models-in-nlp/home/welcome) of our [Natural Language Processing Specialization](https://www.coursera.org/specializations/natural-language-processing?=) where you can learn how to build Transformers and perform QA using the [Trax](https://trax.readthedocs.io/en/latest/) library. \n",
    "\n",
    "<a name='1-1'></a>\n",
    "### 1.1 - Data preprocessing\n",
    "\n",
    "Run the following cell to load the [QA bAbI dataset](https://research.fb.com/downloads/babi/), which is one of the bAbI datasets generated by Facebook AI Research to advance natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxU0G_PYLSXJ",
    "outputId": "44e7877f-5c33-45fc-ed83-3aa4920dcc40"
   },
   "outputs": [],
   "source": [
    "# from datasets import load_from_disk\n",
    "\n",
    "# # Load a dataset and print the first example in the training set\n",
    "# babi_dataset = load_from_disk('data/')\n",
    "# print(babi_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['story'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['story'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# babi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration en-10k-qa4-task_no=qa4,type=en-10k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset babi_qa/en-10k-qa4 (download: 14.99 MiB, generated: 2.16 MiB, post-processed: Unknown size, total: 17.15 MiB) to C:\\Users\\Mouli Bhaskar\\.cache\\huggingface\\datasets\\babi_qa\\en-10k-qa4-task_no=qa4,type=en-10k\\1.2.0\\a3c1ff28a1e13b872a34a5aae4a0d6715f4ff95cbc823c7d2c04f278e912dfab...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018575429916381836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating train split",
       "rate": null,
       "total": 10000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4cc26d87c745a0bb166ee5f2c52e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01613759994506836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating test split",
       "rate": null,
       "total": 1000,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb2b6877dfd45969b35f42d53f8211b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset babi_qa downloaded and prepared to C:\\Users\\Mouli Bhaskar\\.cache\\huggingface\\datasets\\babi_qa\\en-10k-qa4-task_no=qa4,type=en-10k\\1.2.0\\a3c1ff28a1e13b872a34a5aae4a0d6715f4ff95cbc823c7d2c04f278e912dfab. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016300678253173828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ab3bb741d848ea8bcca76d1187db87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'story': {'id': ['1', '2', '3'], 'type': [0, 0, 1], 'text': ['The office is north of the kitchen.', 'The garden is south of the kitchen.', 'What is north of the kitchen?'], 'supporting_ids': [[], [], ['1']], 'answer': ['', '', 'office']}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a dataset and print the first example in the training set\n",
    "babi_dataset = load_dataset('babi_qa', type='en-10k', task_no='qa4')\n",
    "print(babi_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJwacC3bMhZM"
   },
   "source": [
    "Take a look at the format of the data. For a given story, there are two sentences which serve as the context, and one question. Each of these phrases has an ID. There is also a supporting fact ID which refers to a sentence in the story that helps answer the question. For example, for the question 'What is east of the hallway?', the supporting fact 'The bedroom is east of the hallway' has the ID '2'. There is also the answer, 'bedroom' for the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aizPXfGlLZ1D",
    "outputId": "0e1d47bc-9c1a-458a-983e-22f47f8184bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['story'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['story'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babi_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewtXZUPjMm2l"
   },
   "source": [
    "Check and see if the entire dataset of stories has this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "55BSWxwuM1hN"
   },
   "outputs": [],
   "source": [
    "type_set = set()\n",
    "for story in babi_dataset['train']:\n",
    "    if str(story['story']['type'] )not in type_set:\n",
    "        type_set.add(str(story['story']['type'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdJ8VMF1UT7S",
    "outputId": "2b959467-75e8-4e25-e7bb-481b657a2fce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 0, 1]'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsHx1tcyMq_k"
   },
   "source": [
    "To make the data easier to work with, you will flatten the dataset to transform it from a dictionary structure to a table structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YxixFI-pVOK9"
   },
   "outputs": [],
   "source": [
    "flattened_babi = babi_dataset.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXU43CqCdX98",
    "outputId": "e968ff5e-0db0-4e9d-e1e9-e93f965b2582"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['story.id', 'story.type', 'story.text', 'story.supporting_ids', 'story.answer'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['story.id', 'story.type', 'story.text', 'story.supporting_ids', 'story.answer'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_babi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQw59MgT6Luh",
    "outputId": "ea5eac53-027e-42d3-d19f-98ed7863de2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story.id': ['1', '2', '3'],\n",
       " 'story.type': [0, 0, 1],\n",
       " 'story.text': ['The office is north of the kitchen.',\n",
       "  'The garden is south of the kitchen.',\n",
       "  'What is north of the kitchen?'],\n",
       " 'story.supporting_ids': [[], [], ['1']],\n",
       " 'story.answer': ['', '', 'office']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(flattened_babi['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vXfmhOPMvt1"
   },
   "source": [
    "Now it is much easier to access the information you need! You can now easily extract the answer, question, and facts from the story, and also join the facts into a single entry under 'sentences'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "O5NcABwkdbrf"
   },
   "outputs": [],
   "source": [
    "def get_question_and_facts(story):\n",
    "    dic = {}\n",
    "    dic['question'] = story['story.text'][2]\n",
    "    dic['sentences'] = ' '.join([story['story.text'][0], story['story.text'][1]])\n",
    "    dic['answer'] = story['story.answer'][2]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "44b7bea3e09d4e5684921c66dd4c7514",
      "6af3ec5091d74bd1a95bf02a87dd240b",
      "7e1325e57bf9417e93d7ef180794ab3c",
      "3dab28395f3f475d8242e4d4d45ed059",
      "ca722dcd857c433c9058585e31a1673d",
      "7fb1118c0b4443b6b6dbb5803e9ec2e8",
      "58718e12f1b7459989ab5296846c4be6",
      "63b4ebafcead4c0784b5511219a6a198",
      "c42644a4e6184a1cbdb2b453b5dbb7d6",
      "364ba960eb474c9084cc71851594d345",
      "e8f1abd85f3e49f991d4c1312ffd416b",
      "929946fdfaa04cf59d3b31cf92fc08d1",
      "aa5c0d374889482697fc0f7ce9c81afe",
      "ff444b253e9a40e5bec755926d83740f",
      "89fdda6e6688476495ca297bfe010bf8",
      "cda72c45821a4eb89f1a3ab5510b26d3"
     ]
    },
    "id": "LHKNQ75afMoZ",
    "outputId": "6ceeae5c-392c-4553-c487-14a648eb9209"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017043113708496094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d7a26674314cbcb4e53152f30fc43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015296459197998047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c722b78802444bf3972dd4b09b56e4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed = flattened_babi.map(get_question_and_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaTacKMufPba",
    "outputId": "2433d446-e985-45cd-a200-f9805b4056bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story.id': ['1', '2', '3'],\n",
       " 'story.type': [0, 0, 1],\n",
       " 'story.text': ['The garden is north of the office.',\n",
       "  'The bedroom is north of the garden.',\n",
       "  'What is north of the garden?'],\n",
       " 'story.supporting_ids': [[], [], ['2']],\n",
       " 'story.answer': ['', '', 'bedroom'],\n",
       " 'question': 'What is north of the garden?',\n",
       " 'sentences': 'The garden is north of the office. The bedroom is north of the garden.',\n",
       " 'answer': 'bedroom'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOrYr5LI0pbP",
    "outputId": "8142f23c-7dab-49b9-8027-fbe7364ae4e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'story.id': ['1', '2', '3'],\n",
       " 'story.type': [0, 0, 1],\n",
       " 'story.text': ['The bathroom is north of the garden.',\n",
       "  'The hallway is north of the bathroom.',\n",
       "  'What is north of the garden?'],\n",
       " 'story.supporting_ids': [[], [], ['1']],\n",
       " 'story.answer': ['', '', 'bathroom'],\n",
       " 'question': 'What is north of the garden?',\n",
       " 'sentences': 'The bathroom is north of the garden. The hallway is north of the bathroom.',\n",
       " 'answer': 'bathroom'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['test'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oN7D3fszM2hy"
   },
   "source": [
    "\n",
    "The goal of extractive QA is to find the part of the text that contains the answer to the question. You will identify the position of the answer using the indexes of the string. For example, if the answer to some question was 'September', you would need to find the start and end string indices of the word 'September' in the context sentence 'Jane visits Africa in September.'\n",
    "\n",
    "\n",
    "Use this next function to get the start and end indices of the answer in each of the stories in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "J1JJx3PafSyR"
   },
   "outputs": [],
   "source": [
    "def get_start_end_idx(story):\n",
    "    str_idx = story['sentences'].find(story['answer'])\n",
    "    end_idx = str_idx + len(story['answer'])\n",
    "    return {'str_idx':str_idx,\n",
    "          'end_idx': end_idx}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "8968319cdaca476fb15c11a388dce39a",
      "863c5ce96db84e3da162072c9a13c913",
      "a725734893004a45b61194f649f5f602",
      "c4a24656d67844e995d3b8e175c6c497",
      "4f5b06c3a5e44c6cade5bf83634d9f69",
      "afc33fa78b5d440192c435bfca6f7914",
      "f37bd346f8614fec92d6c5b5e9b66d2f",
      "b4c6a18610734036a16a14a43174c52e",
      "07aaa9b79a744856b19d723370d6e588",
      "afedd2328cf141f78775e4cfa7758267",
      "b39b85d8cb05418aa92e8476ad02f755",
      "0a8534ac52af4d48ad82b66463ad08c3",
      "3abb36da57c841838867c56e2a3a325b",
      "8b961844b5004905922531bd805a9d57",
      "31fc08a1e7e04f6b9b3ea400ccfaea75",
      "8cfbd3b14b23417993270f851a2d8ff9"
     ]
    },
    "id": "4e7BdgJJhwXi",
    "outputId": "d9c7a923-d2eb-4533-f37e-4f269f22eb89"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020998239517211914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233e64e44b9e44b2be2d8098a39951f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013994932174682617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e0ffa7a1b447e58cd904fbcae5fe17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed = processed.map(get_start_end_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8ytxyfvh0kB",
    "outputId": "c008b161-be24-40bb-a32d-47d92e624787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'story.id': ['1', '2', '3'], 'story.type': [0, 0, 1], 'story.text': ['The hallway is south of the garden.', 'The garden is south of the bedroom.', 'What is south of the bedroom?'], 'story.supporting_ids': [[], [], ['2']], 'story.answer': ['', '', 'garden'], 'question': 'What is south of the bedroom?', 'sentences': 'The hallway is south of the garden. The garden is south of the bedroom.', 'answer': 'garden', 'str_idx': 28, 'end_idx': 34}\n",
      "answer: garden\n"
     ]
    }
   ],
   "source": [
    "num = 187\n",
    "print(processed['test'][num])\n",
    "start_idx = processed['test'][num]['str_idx']\n",
    "end_idx = processed['test'][num]['end_idx']\n",
    "print('answer:', processed['test'][num]['sentences'][start_idx:end_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVX3TA2xM-vJ"
   },
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Tokenize and Align with ðŸ¤— Library\n",
    "\n",
    "Now you have all the data you need to train a Transformer model to perform Question Answering! You are ready for a task you may have already encountered in the Named-Entity Recognition lab - tokenizing and aligning your input. To feed text data to a Transformer model, you will need to tokenize your input using a [ðŸ¤— Transformer tokenizer](https://huggingface.co/transformers/main_classes/tokenizer.html). It is crucial that the tokenizer you use must match the Transformer model type you are using! In this exercise, you will use the ðŸ¤— [DistilBERT fast tokenizer](https://huggingface.co/transformers/model_doc/distilbert.html), which standardizes the length of your sequence to 512 and pads with zeros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c892hk9NNF9O"
   },
   "source": [
    "Transformer models are often trained by tokenizers that split words into subwords. For instance, the word 'Africa' might get split into multiple subtokens. This can create some misalignment between the list of tags for the dataset and the list of labels generated by the tokenizer, since the tokenizer can split one word into several, or add special tokens. Before processing, it is important that you align the start and end indices with the tokens associated with the target answer word with a `tokenize_and_align()` function. In this case, since you are interested in the start and end indices of the answer, you will want to align the index of the sentence to match the index of the token for a word. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UI-9P7VYitxv"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Pex-YXJnnwb9"
   },
   "outputs": [],
   "source": [
    "def tokenize_align(example):\n",
    "    encoding = tokenizer(example['sentences'], example['question'], truncation=True, padding=True, max_length=tokenizer.model_max_length)\n",
    "    start_positions = encoding.char_to_token(example['str_idx'])\n",
    "    end_positions = encoding.char_to_token(example['end_idx']-1)\n",
    "    if start_positions is None:\n",
    "        start_positions = tokenizer.model_max_length\n",
    "    if end_positions is None:\n",
    "        end_positions = tokenizer.model_max_length\n",
    "    return {'input_ids': encoding['input_ids'],\n",
    "          'attention_mask': encoding['attention_mask'],\n",
    "          'start_positions': start_positions,\n",
    "          'end_positions': end_positions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "4d9152a30e824931983a425ee6d607a6",
      "1f2773e3e80c4dd8b6b26e171bf33bc7",
      "013f041c3e0b4e35bf2432fc345cb7bf",
      "ef4e12f29f1e458f811a400faf21bdcc",
      "f0e34f2bf626434fa73f0def26b3d1a5",
      "1e6c02317171453cbd3d4d665879b0d4",
      "5b6dbe662ca24834b7678638e101e1ff",
      "39029f730ae140c7902fca6dac5361ad",
      "723acefae33d448199fa5c1a9ec3f246",
      "32a5c82c7a9845c09c11bb4e30c2f1aa",
      "77273c2e4b4e4e4c8ee4b6b344749518",
      "f0ac3b9b8f664479940c6ee18fc2f13e",
      "393697738e724e9fad4d163de0a77840",
      "e592db98c0c34c5e800f5d7b6d3c099e",
      "568f11b4462f4b4e95f3ad5947bb275e",
      "7fefe9e1121a43558d773500aef8935c"
     ]
    },
    "id": "kKyLNWCvksOr",
    "outputId": "7af3d914-4546-430c-c2f0-206b732e5131"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018039464950561523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3b55ee877d48069ccb3443de1510b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015000104904174805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f386553a8a64021b8b4517f60343b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_dataset = processed.map(tokenize_align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8v5odGZBmGw0"
   },
   "outputs": [],
   "source": [
    "qa_dataset = qa_dataset.remove_columns(['story.answer', 'story.id', 'story.supporting_ids', 'story.text', 'story.type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBHzbjffmJa8",
    "outputId": "b0688636-fdec-4de0-c2d9-69372b1ddbac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is north of the bathroom?',\n",
       " 'sentences': 'The garden is north of the bathroom. The hallway is south of the bathroom.',\n",
       " 'answer': 'garden',\n",
       " 'str_idx': 4,\n",
       " 'end_idx': 10,\n",
       " 'input_ids': [101,\n",
       "  1996,\n",
       "  3871,\n",
       "  2003,\n",
       "  2167,\n",
       "  1997,\n",
       "  1996,\n",
       "  5723,\n",
       "  1012,\n",
       "  1996,\n",
       "  6797,\n",
       "  2003,\n",
       "  2148,\n",
       "  1997,\n",
       "  1996,\n",
       "  5723,\n",
       "  1012,\n",
       "  102,\n",
       "  2054,\n",
       "  2003,\n",
       "  2167,\n",
       "  1997,\n",
       "  1996,\n",
       "  5723,\n",
       "  1029,\n",
       "  102],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'start_positions': 2,\n",
       " 'end_positions': 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset['train'][200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qw79BQfW4feu"
   },
   "source": [
    "<font color='blue'><b>What you should remember:</b>\n",
    "- The goal of *extractive* QA is to identify the portion of the text that contains the answer to a question.\n",
    "- Transformer models are often trained by tokenizers that split words into subwords.\n",
    "  - Before processing, it is important that you align the start and end indices with the tokens associated with the target answer word.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFfJozZvNZWG"
   },
   "source": [
    "<a name='2'></a>\n",
    "# 2 - Training \n",
    "\n",
    "Now that you have finished tokenizing and aligning your data, you can feed it into a pre-trained ðŸ¤— Transformer model! You will use a DistilBERT model, which matches the tokenizer you used to preprocess your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "8sdX5XY0Gwwc"
   },
   "outputs": [],
   "source": [
    "train_ds = qa_dataset['train']\n",
    "test_ds = qa_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Be5k3ilHsJ6q",
    "outputId": "f2f7fea3-1394-4aaf-b159-994a38476994"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at model/tensorflow were not used when initializing TFDistilBertForQuestionAnswering: ['vocab_projector', 'vocab_transform', 'vocab_layer_norm', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at model/tensorflow and are newly initialized: ['qa_outputs', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForQuestionAnswering\n",
    "model = TFDistilBertForQuestionAnswering.from_pretrained(\"model/tensorflow\", return_dict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aQVOG4ANcd2"
   },
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1 - TensorFlow implementation\n",
    "For this assignment you will execute two implemenations, one in TensorFlow and one in PyTorch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pCRo_parYMc"
   },
   "source": [
    "\n",
    "#### Train and test datasets\n",
    "\n",
    "**Note:**\n",
    "* In the TensorFlow implementation, you will have to set the data format type to tensors, which may create ragged tensors (tensors of different lengths). \n",
    "* You will have to convert the ragged tensors to normal tensors using the `to_tensor()` method, which pads the tensors and sets the dimensions to `[None, tokenizer.model_max_length]` so you can feed different size tensors into your model based on the batch size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FbpplBxNtanH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "columns_to_return = ['input_ids','attention_mask', 'start_positions', 'end_positions']\n",
    "\n",
    "train_ds.set_format(type='tf', columns=columns_to_return)\n",
    "\n",
    "train_features = {x: train_ds[x] for x in ['input_ids', 'attention_mask']}\n",
    "train_labels = {\"start_positions\": tf.reshape(train_ds['start_positions'], shape=[-1,1]),\n",
    "                'end_positions': tf.reshape(train_ds['end_positions'], shape=[-1,1])}\n",
    "\n",
    "\n",
    "train_tfdataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).batch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_Jj8Av6rEuN"
   },
   "source": [
    "#### Training \n",
    "\n",
    "It is finally time to start training your model! \n",
    "\n",
    "* Create a custom training function using [tf.GradientTape()](https://www.tensorflow.org/api_docs/python/tf/GradientTape)\n",
    "* Target two loss functions, one for the start index and one for the end index. \n",
    "* `tf.GradientTape()` records the operations performed during forward prop for automatic differentiation during backprop. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtZz249vQbLn",
    "outputId": "24cdf861-af63-4581-a0ae-2de29d1880ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0\n",
      "Training loss (for one batch) at step 0: 3.5389\n",
      "Training loss (for one batch) at step 20: 1.2741\n",
      "Training loss (for one batch) at step 40: 0.7110\n",
      "Training loss (for one batch) at step 60: 0.6747\n",
      "Training loss (for one batch) at step 80: 0.6130\n",
      "Training loss (for one batch) at step 100: 0.1645\n",
      "Training loss (for one batch) at step 120: 0.5623\n",
      "Training loss (for one batch) at step 140: 0.7619\n",
      "Training loss (for one batch) at step 160: 0.5636\n",
      "Training loss (for one batch) at step 180: 0.3834\n",
      "Training loss (for one batch) at step 200: 0.2037\n",
      "Training loss (for one batch) at step 220: 0.5618\n",
      "Training loss (for one batch) at step 240: 0.3132\n",
      "Training loss (for one batch) at step 260: 0.2045\n",
      "Training loss (for one batch) at step 280: 0.3005\n",
      "Training loss (for one batch) at step 300: 0.4834\n",
      "Training loss (for one batch) at step 320: 0.2592\n",
      "Training loss (for one batch) at step 340: 0.3739\n",
      "Training loss (for one batch) at step 360: 0.2803\n",
      "Training loss (for one batch) at step 380: 0.2625\n",
      "Training loss (for one batch) at step 400: 0.3405\n",
      "Training loss (for one batch) at step 420: 0.2813\n",
      "Training loss (for one batch) at step 440: 0.3492\n",
      "Training loss (for one batch) at step 460: 0.4835\n",
      "Training loss (for one batch) at step 480: 0.3756\n",
      "Training loss (for one batch) at step 500: 0.3328\n",
      "Training loss (for one batch) at step 520: 0.1972\n",
      "Training loss (for one batch) at step 540: 0.2464\n",
      "Training loss (for one batch) at step 560: 0.4800\n",
      "Training loss (for one batch) at step 580: 0.2954\n",
      "Training loss (for one batch) at step 600: 0.0499\n",
      "Training loss (for one batch) at step 620: 0.2264\n",
      "Training loss (for one batch) at step 640: 0.1793\n",
      "Training loss (for one batch) at step 660: 0.1132\n",
      "Training loss (for one batch) at step 680: 0.1178\n",
      "Training loss (for one batch) at step 700: 0.2284\n",
      "Training loss (for one batch) at step 720: 0.3377\n",
      "Training loss (for one batch) at step 740: 0.3064\n",
      "Training loss (for one batch) at step 760: 0.0915\n",
      "Training loss (for one batch) at step 780: 0.0753\n",
      "Training loss (for one batch) at step 800: 0.0236\n",
      "Training loss (for one batch) at step 820: 0.0031\n",
      "Training loss (for one batch) at step 840: 0.0216\n",
      "Training loss (for one batch) at step 860: 0.0425\n",
      "Training loss (for one batch) at step 880: 0.0047\n",
      "Training loss (for one batch) at step 900: 0.0075\n",
      "Training loss (for one batch) at step 920: 0.0014\n",
      "Training loss (for one batch) at step 940: 0.0018\n",
      "Training loss (for one batch) at step 960: 0.0003\n",
      "Training loss (for one batch) at step 980: 0.0008\n",
      "Training loss (for one batch) at step 1000: 0.0008\n",
      "Training loss (for one batch) at step 1020: 0.0007\n",
      "Training loss (for one batch) at step 1040: 0.0005\n",
      "Training loss (for one batch) at step 1060: 0.0023\n",
      "Training loss (for one batch) at step 1080: 0.0006\n",
      "Training loss (for one batch) at step 1100: 0.0004\n",
      "Training loss (for one batch) at step 1120: 0.0005\n",
      "Training loss (for one batch) at step 1140: 0.0004\n",
      "Training loss (for one batch) at step 1160: 0.0005\n",
      "Training loss (for one batch) at step 1180: 0.0004\n",
      "Training loss (for one batch) at step 1200: 0.0003\n",
      "Training loss (for one batch) at step 1220: 0.0004\n",
      "Training loss (for one batch) at step 1240: 0.0004\n",
      "Starting epoch: 1\n",
      "Training loss (for one batch) at step 0: 0.0003\n",
      "Training loss (for one batch) at step 20: 0.0004\n",
      "Training loss (for one batch) at step 40: 0.0002\n",
      "Training loss (for one batch) at step 60: 0.0002\n",
      "Training loss (for one batch) at step 80: 0.0003\n",
      "Training loss (for one batch) at step 100: 0.0001\n",
      "Training loss (for one batch) at step 120: 0.0003\n",
      "Training loss (for one batch) at step 140: 0.0001\n",
      "Training loss (for one batch) at step 160: 0.0002\n",
      "Training loss (for one batch) at step 180: 0.0001\n",
      "Training loss (for one batch) at step 200: 0.0001\n",
      "Training loss (for one batch) at step 220: 0.0001\n",
      "Training loss (for one batch) at step 240: 0.0003\n",
      "Training loss (for one batch) at step 260: 0.0002\n",
      "Training loss (for one batch) at step 280: 0.0002\n",
      "Training loss (for one batch) at step 300: 0.0001\n",
      "Training loss (for one batch) at step 320: 0.0001\n",
      "Training loss (for one batch) at step 340: 0.0001\n",
      "Training loss (for one batch) at step 360: 0.0001\n",
      "Training loss (for one batch) at step 380: 0.0001\n",
      "Training loss (for one batch) at step 400: 0.0002\n",
      "Training loss (for one batch) at step 420: 0.0001\n",
      "Training loss (for one batch) at step 440: 0.0001\n",
      "Training loss (for one batch) at step 460: 0.0001\n",
      "Training loss (for one batch) at step 480: 0.0001\n",
      "Training loss (for one batch) at step 500: 0.0001\n",
      "Training loss (for one batch) at step 520: 0.0001\n",
      "Training loss (for one batch) at step 540: 0.0001\n",
      "Training loss (for one batch) at step 560: 0.0001\n",
      "Training loss (for one batch) at step 580: 0.0001\n",
      "Training loss (for one batch) at step 600: 0.0001\n",
      "Training loss (for one batch) at step 620: 0.0001\n",
      "Training loss (for one batch) at step 640: 0.0001\n",
      "Training loss (for one batch) at step 660: 0.0001\n",
      "Training loss (for one batch) at step 680: 0.0001\n",
      "Training loss (for one batch) at step 700: 0.0001\n",
      "Training loss (for one batch) at step 720: 0.0001\n",
      "Training loss (for one batch) at step 740: 0.0001\n",
      "Training loss (for one batch) at step 760: 0.0000\n",
      "Training loss (for one batch) at step 780: 0.0001\n",
      "Training loss (for one batch) at step 800: 0.0001\n",
      "Training loss (for one batch) at step 820: 0.0001\n",
      "Training loss (for one batch) at step 840: 0.0001\n",
      "Training loss (for one batch) at step 860: 0.0001\n",
      "Training loss (for one batch) at step 880: 0.0000\n",
      "Training loss (for one batch) at step 900: 0.0001\n",
      "Training loss (for one batch) at step 920: 0.0001\n",
      "Training loss (for one batch) at step 940: 0.0001\n",
      "Training loss (for one batch) at step 960: 0.0000\n",
      "Training loss (for one batch) at step 980: 0.0001\n",
      "Training loss (for one batch) at step 1000: 0.0001\n",
      "Training loss (for one batch) at step 1020: 0.0001\n",
      "Training loss (for one batch) at step 1040: 0.0001\n",
      "Training loss (for one batch) at step 1060: 0.0001\n",
      "Training loss (for one batch) at step 1080: 0.0001\n",
      "Training loss (for one batch) at step 1100: 0.0001\n",
      "Training loss (for one batch) at step 1120: 0.0001\n",
      "Training loss (for one batch) at step 1140: 0.0001\n",
      "Training loss (for one batch) at step 1160: 0.0001\n",
      "Training loss (for one batch) at step 1180: 0.0001\n",
      "Training loss (for one batch) at step 1200: 0.0001\n",
      "Training loss (for one batch) at step 1220: 0.0001\n",
      "Training loss (for one batch) at step 1240: 0.0001\n",
      "Starting epoch: 2\n",
      "Training loss (for one batch) at step 0: 0.0001\n",
      "Training loss (for one batch) at step 20: 0.0000\n",
      "Training loss (for one batch) at step 40: 0.0000\n",
      "Training loss (for one batch) at step 60: 0.0000\n",
      "Training loss (for one batch) at step 80: 0.0001\n",
      "Training loss (for one batch) at step 100: 0.0000\n",
      "Training loss (for one batch) at step 120: 0.0001\n",
      "Training loss (for one batch) at step 140: 0.0000\n",
      "Training loss (for one batch) at step 160: 0.0000\n",
      "Training loss (for one batch) at step 180: 0.0000\n",
      "Training loss (for one batch) at step 200: 0.0000\n",
      "Training loss (for one batch) at step 220: 0.0000\n",
      "Training loss (for one batch) at step 240: 0.0000\n",
      "Training loss (for one batch) at step 260: 0.0000\n",
      "Training loss (for one batch) at step 280: 0.0000\n",
      "Training loss (for one batch) at step 300: 0.0000\n",
      "Training loss (for one batch) at step 320: 0.0000\n",
      "Training loss (for one batch) at step 340: 0.0000\n",
      "Training loss (for one batch) at step 360: 0.0000\n",
      "Training loss (for one batch) at step 380: 0.0000\n",
      "Training loss (for one batch) at step 400: 0.0001\n",
      "Training loss (for one batch) at step 420: 0.0000\n",
      "Training loss (for one batch) at step 440: 0.0000\n",
      "Training loss (for one batch) at step 460: 0.0001\n",
      "Training loss (for one batch) at step 480: 0.0000\n",
      "Training loss (for one batch) at step 500: 0.0000\n",
      "Training loss (for one batch) at step 520: 0.0000\n",
      "Training loss (for one batch) at step 540: 0.0000\n",
      "Training loss (for one batch) at step 560: 0.0000\n",
      "Training loss (for one batch) at step 580: 0.0000\n",
      "Training loss (for one batch) at step 600: 0.0000\n",
      "Training loss (for one batch) at step 620: 0.0000\n",
      "Training loss (for one batch) at step 640: 0.0000\n",
      "Training loss (for one batch) at step 660: 0.0000\n",
      "Training loss (for one batch) at step 680: 0.0000\n",
      "Training loss (for one batch) at step 700: 0.0000\n",
      "Training loss (for one batch) at step 720: 0.0000\n",
      "Training loss (for one batch) at step 740: 0.0000\n",
      "Training loss (for one batch) at step 760: 0.0000\n",
      "Training loss (for one batch) at step 780: 0.0000\n",
      "Training loss (for one batch) at step 800: 0.0000\n",
      "Training loss (for one batch) at step 820: 0.0000\n",
      "Training loss (for one batch) at step 840: 0.0000\n",
      "Training loss (for one batch) at step 860: 0.0000\n",
      "Training loss (for one batch) at step 880: 0.0000\n",
      "Training loss (for one batch) at step 900: 0.0000\n",
      "Training loss (for one batch) at step 920: 0.0000\n",
      "Training loss (for one batch) at step 940: 0.0000\n",
      "Training loss (for one batch) at step 960: 0.0000\n",
      "Training loss (for one batch) at step 980: 0.0000\n",
      "Training loss (for one batch) at step 1000: 0.0000\n",
      "Training loss (for one batch) at step 1020: 0.0000\n",
      "Training loss (for one batch) at step 1040: 0.0000\n",
      "Training loss (for one batch) at step 1060: 0.0000\n",
      "Training loss (for one batch) at step 1080: 0.0000\n",
      "Training loss (for one batch) at step 1100: 0.0000\n",
      "Training loss (for one batch) at step 1120: 0.0000\n",
      "Training loss (for one batch) at step 1140: 0.0000\n",
      "Training loss (for one batch) at step 1160: 0.0000\n",
      "Training loss (for one batch) at step 1180: 0.0000\n",
      "Training loss (for one batch) at step 1200: 0.0000\n",
      "Training loss (for one batch) at step 1220: 0.0000\n",
      "Training loss (for one batch) at step 1240: 0.0000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "loss_fn1 = tf.keras.losses.SparseCategoricalCrossentropy( from_logits=True)\n",
    "loss_fn2 = tf.keras.losses.SparseCategoricalCrossentropy( from_logits=True)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Starting epoch: %d\"% epoch )\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_tfdataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            answer_start_scores, answer_end_scores = model(x_batch_train)\n",
    "            loss_start = loss_fn1(y_batch_train['start_positions'], answer_start_scores)\n",
    "            loss_end = loss_fn2(y_batch_train['end_positions'], answer_end_scores)\n",
    "            loss = 0.5 * (loss_start + loss_end)\n",
    "        losses.append(loss)\n",
    "        grads = tape.gradient(loss, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(\"Training loss (for one batch) at step %d: %.4f\"% (step, \n",
    "                                                                   float(loss_start)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8ggB0JUWQuW"
   },
   "source": [
    "Take a look at your losses and try playing around with some of the hyperparameters for better results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "fK91EPvRYFcX",
    "outputId": "6b7099dd-f918-4905-e3a3-fcce2880e506"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a6393c66b0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import plot\n",
    "\n",
    "plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64OtEmyUWUiM"
   },
   "source": [
    "You have successfully trained your model to help automatically answer questions! Try asking it a question about a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFniMzpp1bpz",
    "outputId": "0ce0e2a3-3d6a-4e6e-adff-d0c16b622c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who addressed the nation? ##kir\n"
     ]
    }
   ],
   "source": [
    "question, text = 'Who addressed the nation?','President Dr Zakir Husain recording Address to the Nation at the TV studio in the All India Radio.'\n",
    "input_dict = tokenizer(text, question, return_tensors='tf')\n",
    "outputs = model(input_dict)\n",
    "start_logits = outputs[0]\n",
    "end_logits = outputs[1]\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"].numpy()[0])\n",
    "answer = ' '.join(all_tokens[tf.math.argmax(start_logits, 1)[0] : tf.math.argmax(end_logits, 1)[0]+1])\n",
    "print(question, answer.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f07OtnCpuKFa"
   },
   "source": [
    "Congratulations! You just implemented your first QA model in TensorFlow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UaM5pY9u8EW"
   },
   "source": [
    "<a name='2-1'></a>\n",
    "## 2.2 PyTorch implementation\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is an open source machine learning framework developed by Facebook's AI Research lab that can be used for computer vision and natural language processing. As you can imagine, it is quite compatible with the bAbI dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nD9akXoXxMjd"
   },
   "source": [
    "#### Train and test dataset\n",
    "\n",
    "Go ahead and try creating a train and test dataset by importing PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "JxMYWSG173ch"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "columns_to_return = ['input_ids','attention_mask', 'start_positions', 'end_positions']\n",
    "train_ds.set_format(type='pt', columns=columns_to_return)\n",
    "test_ds.set_format(type='pt', columns=columns_to_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeuzZKlPHAAQ"
   },
   "source": [
    "For the accuracy metrics for the PyTorch implementation, you will change things up a bit and use the [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) for start and end indicies over the entire test dataset as the loss functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "aD9tDpZfJsIB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    start_labels = pred.label_ids[0]\n",
    "    start_preds = pred.predictions[0].argmax(-1)\n",
    "    end_labels = pred.label_ids[1]\n",
    "    end_preds = pred.predictions[1].argmax(-1)\n",
    "    \n",
    "    f1_start = f1_score(start_labels, start_preds, average='macro')\n",
    "    f1_end = f1_score(end_labels, end_preds, average='macro')\n",
    "    \n",
    "    return {\n",
    "        'f1_start': f1_start,\n",
    "        'f1_end': f1_end,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laX5cYQRHMXb"
   },
   "source": [
    "#### Training\n",
    "\n",
    "Now it is time to load a pre-trained model. \n",
    "\n",
    "**Note:** You will be using the DistilBERT instead of TFDistilBERT for a PyTorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model # We delete the tensorflow model to avoid memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXFCsNcY79jx",
    "outputId": "09af112f-e1e9-4a47-c988-37ee2a068df2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing DistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of DistilBertForQuestionAnswering were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForQuestionAnswering\n",
    "\n",
    "pytorch_model = DistilBertForQuestionAnswering.from_pretrained(\"model/pytorch\", from_tf = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCUdMmCxHP6_"
   },
   "source": [
    "Instead of a custom training loop, you will use the [ðŸ¤— Trainer](https://huggingface.co/transformers/main_classes/trainer.html), which contains a basic training loop and is fairly easy to implement in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "1htmS3TV-2Bk",
    "outputId": "cc21bfbb-da09-47f9-ee16-7db0096d35e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: end_idx, question, sentences, str_idx, answer. If end_idx, question, sentences, str_idx, answer are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\Mouli Bhaskar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1250\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03398585319519043,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1250,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b29e044b9b84ff2b7325bc63a9397fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4738, 'learning_rate': 4.878048780487805e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7104, 'learning_rate': 4.6747967479674795e-05, 'epoch': 0.8}\n",
      "{'loss': 0.6286, 'learning_rate': 4.4715447154471546e-05, 'epoch': 1.2}\n",
      "{'loss': 0.5704, 'learning_rate': 4.26829268292683e-05, 'epoch': 1.6}\n",
      "{'loss': 0.4313, 'learning_rate': 4.065040650406504e-05, 'epoch': 2.0}\n",
      "{'loss': 0.3465, 'learning_rate': 3.861788617886179e-05, 'epoch': 2.4}\n",
      "{'loss': 0.376, 'learning_rate': 3.6585365853658535e-05, 'epoch': 2.8}\n",
      "{'loss': 0.3182, 'learning_rate': 3.4552845528455286e-05, 'epoch': 3.2}\n",
      "{'loss': 0.3394, 'learning_rate': 3.2520325203252037e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results\\checkpoint-500\n",
      "Configuration saved in results\\checkpoint-500\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2356, 'learning_rate': 3.048780487804878e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0847, 'learning_rate': 2.8455284552845528e-05, 'epoch': 4.4}\n",
      "{'loss': 0.0358, 'learning_rate': 2.642276422764228e-05, 'epoch': 4.8}\n",
      "{'loss': 0.0498, 'learning_rate': 2.4390243902439026e-05, 'epoch': 5.2}\n",
      "{'loss': 0.0046, 'learning_rate': 2.2357723577235773e-05, 'epoch': 5.6}\n",
      "{'loss': 0.0218, 'learning_rate': 2.032520325203252e-05, 'epoch': 6.0}\n",
      "{'loss': 0.0045, 'learning_rate': 1.8292682926829268e-05, 'epoch': 6.4}\n",
      "{'loss': 0.0016, 'learning_rate': 1.6260162601626018e-05, 'epoch': 6.8}\n",
      "{'loss': 0.0179, 'learning_rate': 1.4227642276422764e-05, 'epoch': 7.2}\n",
      "{'loss': 0.0006, 'learning_rate': 1.2195121951219513e-05, 'epoch': 7.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results\\checkpoint-1000\n",
      "Configuration saved in results\\checkpoint-1000\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0055, 'learning_rate': 1.016260162601626e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in results\\checkpoint-1000\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0009, 'learning_rate': 8.130081300813009e-06, 'epoch': 8.4}\n",
      "{'loss': 0.0003, 'learning_rate': 6.0975609756097564e-06, 'epoch': 8.8}\n",
      "{'loss': 0.0273, 'learning_rate': 4.0650406504065046e-06, 'epoch': 9.2}\n",
      "{'loss': 0.0063, 'learning_rate': 2.0325203252032523e-06, 'epoch': 9.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "{'train_runtime': 1712.8147, 'train_samples_per_second': 5.838, 'train_steps_per_second': 0.73, 'train_loss': 0.2277151036813855, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.2277151036813855, metrics={'train_runtime': 1712.8147, 'train_samples_per_second': 5.838, 'train_steps_per_second': 0.73, 'train_loss': 0.2277151036813855, 'epoch': 10.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='results',          # output directory\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    warmup_steps=20,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=None,            # directory for storing logs\n",
    "    logging_steps=50\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=pytorch_model,                 # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_ds,         # training dataset\n",
    "    eval_dataset=test_ds,\n",
    "    compute_metrics=compute_metrics             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "lDzbm7vzAiPJ",
    "outputId": "7cd62f51-a04b-4583-bc0e-e459813d3103"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: end_idx, question, sentences, str_idx, answer. If end_idx, question, sentences, str_idx, answer are not expected by `DistilBertForQuestionAnswering.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03165173530578613,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 125,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57d62ab90a643ba82cce7498c05ad72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.154208676889539e-05,\n",
       " 'eval_f1_start': 1.0,\n",
       " 'eval_f1_end': 1.0,\n",
       " 'eval_runtime': 25.3369,\n",
       " 'eval_samples_per_second': 39.468,\n",
       " 'eval_steps_per_second': 4.934,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAgrcs2pHvVu"
   },
   "source": [
    "Now it is time to ask your PyTorch model a question! \n",
    "* Before testing your model with a question, you can tell PyTorch to send your model and inputs to the GPU if your machine has one, or the CPU if it does not. \n",
    "* You can then proceed to tokenize your input and create PyTorch tensors and send them to your device. \n",
    "* The rest of the pipeline is relatively similar to the one you implemented for TensorFlow.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfBe9AFABqUr",
    "outputId": "b5ca6039-8ce2-4e75-9161-1c96a0f39425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is my name? \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "pytorch_model.to(device)\n",
    "\n",
    "question, text = 'What is my name?','My name is Mouli.'\n",
    "\n",
    "input_dict = tokenizer(text, question, return_tensors='pt')\n",
    "\n",
    "input_ids = input_dict['input_ids'].to(device)\n",
    "attention_mask = input_dict['attention_mask'].to(device)\n",
    "\n",
    "outputs = pytorch_model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "start_logits = outputs[0]\n",
    "end_logits = outputs[1]\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"].numpy()[0])\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_logits, 1)[0] : torch.argmax(end_logits, 1)[0]+1])\n",
    "\n",
    "print(question, answer.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGzuHkMZ4q9I"
   },
   "source": [
    "### Congratulations!\n",
    " \n",
    "You've completed this notebook, and can now implement Transformer models for QA tasks!\n",
    "\n",
    "You are now able to:\n",
    "* Perform extractive Question Answering \n",
    "* Fine-tune a pre-trained transformer model to a custom dataset\n",
    "* Implement a QA model in TensorFlow and PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8tAV-584vKE"
   },
   "source": [
    "<font color='blue'><b>What you should remember</b>:\n",
    "- Transformer models are often trained by tokenizers that split words into subwords.\n",
    "  - Before processing, it is important that you align the start and end indices with the tokens associated with the target answer word.\n",
    "- PyTorch is a relatively light and easy to implement framework that can make rapid prototyping easier, while TensorFlow has advantages in scaling and is more widely used in production\n",
    "  - `tf.GradientTape` allows you to build custom training loops in TensorFlow\n",
    "  - The `Trainer` API in PyTorch gives you a basic training loop that is compatible with ðŸ¤— models and datasets"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "QA-dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "32fcfa82b97a985ea3aa2e49a3e569540fe321e0e602e8c34d530c4d54634e95"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "013f041c3e0b4e35bf2432fc345cb7bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e6c02317171453cbd3d4d665879b0d4",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f0e34f2bf626434fa73f0def26b3d1a5",
      "value": 1000
     }
    },
    "07aaa9b79a744856b19d723370d6e588": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b39b85d8cb05418aa92e8476ad02f755",
       "IPY_MODEL_0a8534ac52af4d48ad82b66463ad08c3"
      ],
      "layout": "IPY_MODEL_afedd2328cf141f78775e4cfa7758267"
     }
    },
    "0a8534ac52af4d48ad82b66463ad08c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cfbd3b14b23417993270f851a2d8ff9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_31fc08a1e7e04f6b9b3ea400ccfaea75",
      "value": " 1000/1000 [01:40&lt;00:00,  9.90ex/s]"
     }
    },
    "1e6c02317171453cbd3d4d665879b0d4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f2773e3e80c4dd8b6b26e171bf33bc7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31fc08a1e7e04f6b9b3ea400ccfaea75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32a5c82c7a9845c09c11bb4e30c2f1aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "364ba960eb474c9084cc71851594d345": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39029f730ae140c7902fca6dac5361ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "393697738e724e9fad4d163de0a77840": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3abb36da57c841838867c56e2a3a325b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3dab28395f3f475d8242e4d4d45ed059": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63b4ebafcead4c0784b5511219a6a198",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_58718e12f1b7459989ab5296846c4be6",
      "value": " 1000/1000 [00:10&lt;00:00, 97.35ex/s]"
     }
    },
    "44b7bea3e09d4e5684921c66dd4c7514": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e1325e57bf9417e93d7ef180794ab3c",
       "IPY_MODEL_3dab28395f3f475d8242e4d4d45ed059"
      ],
      "layout": "IPY_MODEL_6af3ec5091d74bd1a95bf02a87dd240b"
     }
    },
    "4d9152a30e824931983a425ee6d607a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_013f041c3e0b4e35bf2432fc345cb7bf",
       "IPY_MODEL_ef4e12f29f1e458f811a400faf21bdcc"
      ],
      "layout": "IPY_MODEL_1f2773e3e80c4dd8b6b26e171bf33bc7"
     }
    },
    "4f5b06c3a5e44c6cade5bf83634d9f69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "568f11b4462f4b4e95f3ad5947bb275e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58718e12f1b7459989ab5296846c4be6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b6dbe662ca24834b7678638e101e1ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63b4ebafcead4c0784b5511219a6a198": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6af3ec5091d74bd1a95bf02a87dd240b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "723acefae33d448199fa5c1a9ec3f246": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77273c2e4b4e4e4c8ee4b6b344749518",
       "IPY_MODEL_f0ac3b9b8f664479940c6ee18fc2f13e"
      ],
      "layout": "IPY_MODEL_32a5c82c7a9845c09c11bb4e30c2f1aa"
     }
    },
    "77273c2e4b4e4e4c8ee4b6b344749518": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e592db98c0c34c5e800f5d7b6d3c099e",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_393697738e724e9fad4d163de0a77840",
      "value": 1000
     }
    },
    "7e1325e57bf9417e93d7ef180794ab3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fb1118c0b4443b6b6dbb5803e9ec2e8",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca722dcd857c433c9058585e31a1673d",
      "value": 1000
     }
    },
    "7fb1118c0b4443b6b6dbb5803e9ec2e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fefe9e1121a43558d773500aef8935c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "863c5ce96db84e3da162072c9a13c913": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8968319cdaca476fb15c11a388dce39a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a725734893004a45b61194f649f5f602",
       "IPY_MODEL_c4a24656d67844e995d3b8e175c6c497"
      ],
      "layout": "IPY_MODEL_863c5ce96db84e3da162072c9a13c913"
     }
    },
    "89fdda6e6688476495ca297bfe010bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b961844b5004905922531bd805a9d57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cfbd3b14b23417993270f851a2d8ff9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "929946fdfaa04cf59d3b31cf92fc08d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cda72c45821a4eb89f1a3ab5510b26d3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_89fdda6e6688476495ca297bfe010bf8",
      "value": " 1000/1000 [00:08&lt;00:00, 123.32ex/s]"
     }
    },
    "a725734893004a45b61194f649f5f602": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afc33fa78b5d440192c435bfca6f7914",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f5b06c3a5e44c6cade5bf83634d9f69",
      "value": 1000
     }
    },
    "aa5c0d374889482697fc0f7ce9c81afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "afc33fa78b5d440192c435bfca6f7914": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afedd2328cf141f78775e4cfa7758267": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b39b85d8cb05418aa92e8476ad02f755": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b961844b5004905922531bd805a9d57",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3abb36da57c841838867c56e2a3a325b",
      "value": 1000
     }
    },
    "b4c6a18610734036a16a14a43174c52e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c42644a4e6184a1cbdb2b453b5dbb7d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e8f1abd85f3e49f991d4c1312ffd416b",
       "IPY_MODEL_929946fdfaa04cf59d3b31cf92fc08d1"
      ],
      "layout": "IPY_MODEL_364ba960eb474c9084cc71851594d345"
     }
    },
    "c4a24656d67844e995d3b8e175c6c497": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4c6a18610734036a16a14a43174c52e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f37bd346f8614fec92d6c5b5e9b66d2f",
      "value": " 1000/1000 [01:41&lt;00:00,  9.86ex/s]"
     }
    },
    "ca722dcd857c433c9058585e31a1673d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cda72c45821a4eb89f1a3ab5510b26d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e592db98c0c34c5e800f5d7b6d3c099e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8f1abd85f3e49f991d4c1312ffd416b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff444b253e9a40e5bec755926d83740f",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa5c0d374889482697fc0f7ce9c81afe",
      "value": 1000
     }
    },
    "ef4e12f29f1e458f811a400faf21bdcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39029f730ae140c7902fca6dac5361ad",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5b6dbe662ca24834b7678638e101e1ff",
      "value": " 1000/1000 [01:25&lt;00:00, 11.68ex/s]"
     }
    },
    "f0ac3b9b8f664479940c6ee18fc2f13e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fefe9e1121a43558d773500aef8935c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_568f11b4462f4b4e95f3ad5947bb275e",
      "value": " 1000/1000 [01:24&lt;00:00, 11.77ex/s]"
     }
    },
    "f0e34f2bf626434fa73f0def26b3d1a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f37bd346f8614fec92d6c5b5e9b66d2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff444b253e9a40e5bec755926d83740f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
